

import os
import threading
import time
try:
	import openai
except ImportError:
	openai = None

SYSTEM_PROMPT = (
	"You are an expert vehicle valuation assistant. ONLY use the provided facts. "
	"If you are uncertain, say so. Do not invent or speculate."
)

def llm_explanation(numeric_output: dict, top_factors: list, method: str, data_sufficiency: bool, timeout=5, ensemble_factors=None):
	api_key = os.environ.get("OPENAI_API_KEY")
	if openai is None or not api_key:
		# Fallback if openai is not installed or API key missing
		user_prompt = (
			f"Valuation result: {numeric_output}.\n"
			f"Top factors: {top_factors}.\n"
			f"Method: {method}.\n"
			f"Data sufficiency: {data_sufficiency}.\n"
			f"Ensemble/multimodal factors: {ensemble_factors if ensemble_factors else 'N/A'}.\n"
			"Write a user-friendly, facts-only explanation. Only reference features and factors present above."
		)
		return {
			"prompt": user_prompt,
			"explanation": "OpenAI package not installed or API key missing. This is a factual, user-friendly explanation generated by a stub."
		}
	openai.api_key = api_key
	user_prompt = (
		f"Valuation result: {numeric_output}.\n"
		f"Top factors: {top_factors}.\n"
		f"Method: {method}.\n"
		f"Data sufficiency: {data_sufficiency}.\n"
		f"Ensemble/multimodal factors: {ensemble_factors if ensemble_factors else 'N/A'}.\n"
		"Write a user-friendly, facts-only explanation. Only reference features and factors present above."
	)
	result = {"text": None}
	def call_llm():
		try:
			response = openai.ChatCompletion.create(
				model="gpt-4o",
				messages=[
					{"role": "system", "content": SYSTEM_PROMPT},
					{"role": "user", "content": user_prompt}
				],
				max_tokens=120,
				temperature=0.2,
			)
			result["text"] = response.choices[0].message.content.strip()
		except Exception:
			result["text"] = None
	thread = threading.Thread(target=call_llm)
	thread.start()
	thread.join(timeout)
	if result["text"]:
		return {"prompt": user_prompt, "explanation": result["text"]}
	return {"prompt": user_prompt, "explanation": fallback_explanation(numeric_output, top_factors, method, data_sufficiency)}

def test_llm_explanation():
    result = llm_explanation(
        numeric_output={"value": 12345},
        top_factors=[{"feature": "year", "direction": "positive", "abs_impact": 0.2}],
        method="stacking",
        data_sufficiency=True,
        ensemble_factors=[{"feature": "image:damage", "direction": "negative", "abs_impact": 0.15}]
    )
    assert "facts-only" in result["prompt"]
def fallback_explanation(numeric_output, top_factors, method, data_sufficiency):
	value = numeric_output.get("value", "N/A")
	conf = numeric_output.get("confidence", "N/A")
	if not data_sufficiency:
		return f"The valuation is based on limited data. Estimated value: ${value} (confidence: {conf})."
	factors = ", ".join([f["feature"] for f in top_factors]) if top_factors else "various factors"
	return f"Estimated value: ${value} (confidence: {conf}). Top factors: {factors}."
