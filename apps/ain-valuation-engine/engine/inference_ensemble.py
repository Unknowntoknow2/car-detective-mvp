"""
inference_ensemble.py
====================
Production inference orchestration for advanced stacking ensemble valuation engine.

Features:
- Loads all trained and serialized model artifacts:
    - Tabular XGBoost model
    - Tabular DNN model
    - Image CNN model
    - Text BERT/transformer model
    - Meta-learner (e.g., XGBoost or Ridge)
    - All associated preprocessing pipelines
- For each inference request:
    - Validates and preprocesses each input modality (tabular, image, text) as per the training pipeline
    - Runs each preprocessed input through its corresponding base model to obtain predictions
    - Concatenates all base model outputs into a single feature vector for the meta-learner
    - Runs the meta-learner to obtain the final valuation prediction
- Returns a response including:
    - The final ensemble value
    - Each base modelâ€™s prediction
    - Confidence/range (if modeled)
    - Metadata specifying which models and versions were used

Thread-safe, efficient, and ready for production API integration.

--------------------
Input Format:
--------------------
def predict(tabular: list[float] | np.ndarray = None, image_path: str = None, text: str = None) -> dict

Arguments:
    tabular: List or 1D numpy array of tabular features (must match training order/length)
    image_path: Path to image file (str), or None
    text: Raw text string (e.g., description/notes), or None

--------------------
Output Format:
--------------------
{
    'ensemble_prediction': float,           # Final valuation
    'base_predictions': {
        'tab_xgb': float,
        'tab_dnn': float,
        'img_cnn': float,
        'txt_bert': float
    },
    'confidence': float | None,             # Optional, if modeled
    'meta': {
        'models_used': { ... },
        'model_versions': { ... }
    }
}

--------------------
Error Handling:
--------------------
- Raises ValueError if required modalities are missing or input shapes are invalid.
- Returns zeros for missing modalities (with warning in metadata).

--------------------
Example Usage:
--------------------
from engine.inference_ensemble import EnsembleInferenceEngine
engine = EnsembleInferenceEngine('models')
result = engine.predict(
    tabular=[1.2, 3.4, 5.6, 7.8],
    image_path='example.jpg',
    text='Excellent condition, low mileage.'
)
print(result)

--------------------
Integration Notes:
--------------------
- Thread-safe for concurrent API requests.
- All models loaded once per process; inference is fast and stateless.
- For batch inference, call predict() in a loop or vectorize as needed.
- For API/UI: validate input shape and types before calling predict().
"""
import os
import threading
import numpy as np
import torch
import joblib
from typing import Dict, Any
from ml.image_cnn import ImageCNNRegressor
from ml.text_bert import TextBERTRegressor

# Thread lock for model loading/inference
_model_lock = threading.Lock()

class EnsembleInferenceEngine:
    def __init__(self, model_dir='models'):
        self.model_dir = model_dir
        self._load_all_models()

    def _load_all_models(self):
        with _model_lock:
            # Tabular XGBoost
            self.tab_xgb = joblib.load(os.path.join(self.model_dir, 'tabular_xgb_0.joblib'))
            # Tabular DNN
            self.tab_dnn = self._load_dnn()
            # Image CNN
            self.img_cnn = self._load_cnn()
            # Text BERT
            self.txt_bert = self._load_bert()
            # Meta-learner
            self.meta_learner = joblib.load(os.path.join(self.model_dir, 'meta_learner.joblib'))
            # Tabular scaler
            self.tab_scaler = joblib.load(os.path.join(self.model_dir, 'tab_scaler.joblib')) if os.path.exists(os.path.join(self.model_dir, 'tab_scaler.joblib')) else None
            # Text tokenizer
            self.text_tokenizer = TextBERTRegressor().tokenizer
            if os.path.exists(os.path.join(self.model_dir, 'text_tokenizer')):
                self.text_tokenizer = self.text_tokenizer.from_pretrained(os.path.join(self.model_dir, 'text_tokenizer'))

    def _load_dnn(self):
        from ml.train_ensemble import build_dnn
        dnn = build_dnn(self.tab_xgb.n_features_in_)
        dnn.load_state_dict(torch.load(os.path.join(self.model_dir, 'tabular_dnn_0.pt'), map_location='cpu'))
        dnn.eval()
        return dnn

    def _load_cnn(self):
        model = ImageCNNRegressor()
        model.load_state_dict(torch.load(os.path.join(self.model_dir, 'image_cnn_0.pt'), map_location='cpu'))
        model.eval()
        return model

    def _load_bert(self):
        model = TextBERTRegressor()
        model.load_state_dict(torch.load(os.path.join(self.model_dir, 'text_bert_0.pt'), map_location='cpu'))
        model.eval()
        return model

    def preprocess_tabular(self, X):
        if self.tab_scaler:
            return self.tab_scaler.transform(np.array(X).reshape(1, -1)).astype(np.float32)
        return np.array(X).reshape(1, -1).astype(np.float32)

    def preprocess_image(self, image_path):
        return ImageCNNRegressor.preprocess_image(image_path)

    def preprocess_text(self, text):
        encoding = self.text_tokenizer(text, truncation=True, padding='max_length', max_length=128, return_tensors='pt')
        return encoding['input_ids'], encoding['attention_mask']

    def predict(self, tabular=None, image_path=None, text=None) -> Dict[str, Any]:
        """
        Run inference for a single valuation request.
        Args:
            tabular: List or 1D np.ndarray of tabular features (required if used in training)
            image_path: Path to image file (str), or None
            text: Raw text string, or None
        Returns:
            dict: See module docstring for output format.
        Raises:
            ValueError: If required modalities are missing or input shapes are invalid.
        """
        with _model_lock:
            preds = {}
            meta_features = []
            warnings = []
            # Tabular XGBoost
            if tabular is not None:
                try:
                    X_tab = self.preprocess_tabular(tabular)
                    preds['tab_xgb'] = float(self.tab_xgb.predict(X_tab)[0])
                    X_tab_tensor = torch.tensor(X_tab, dtype=torch.float32)
                    preds['tab_dnn'] = float(self.tab_dnn(X_tab_tensor).detach().numpy().squeeze())
                    meta_features.extend([preds['tab_xgb'], preds['tab_dnn']])
                except Exception as e:
                    warnings.append(f"Tabular input error: {e}")
                    meta_features.extend([0.0, 0.0])
            else:
                warnings.append("Tabular input missing; using zeros.")
                meta_features.extend([0.0, 0.0])
            # Image CNN
            if image_path is not None:
                try:
                    X_img = self.preprocess_image(image_path)
                    preds['img_cnn'] = float(self.img_cnn(X_img).detach().numpy().squeeze())
                    meta_features.append(preds['img_cnn'])
                except Exception as e:
                    warnings.append(f"Image input error: {e}")
                    meta_features.append(0.0)
            else:
                warnings.append("Image input missing; using zero.")
                meta_features.append(0.0)
            # Text BERT
            if text is not None:
                try:
                    input_ids, attn_mask = self.preprocess_text(text)
                    preds['txt_bert'] = float(self.txt_bert(input_ids, attn_mask).detach().numpy().squeeze())
                    meta_features.append(preds['txt_bert'])
                except Exception as e:
                    warnings.append(f"Text input error: {e}")
                    meta_features.append(0.0)
            else:
                warnings.append("Text input missing; using zero.")
                meta_features.append(0.0)
            # Meta-learner ensemble
            meta_X = np.array(meta_features).reshape(1, -1)
            try:
                ensemble_pred = float(self.meta_learner.predict(meta_X)[0])
            except Exception as e:
                warnings.append(f"Meta-learner error: {e}")
                ensemble_pred = 0.0
            # Metadata
            meta = {
                'models_used': {
                    'tab_xgb': hasattr(self, 'tab_xgb'),
                    'tab_dnn': hasattr(self, 'tab_dnn'),
                    'img_cnn': hasattr(self, 'img_cnn'),
                    'txt_bert': hasattr(self, 'txt_bert'),
                    'meta_learner': hasattr(self, 'meta_learner')
                },
                'model_versions': {
                    'tab_xgb': getattr(self.tab_xgb, 'get_booster', lambda: None)(),
                    'tab_dnn': 'v1',
                    'img_cnn': 'v1',
                    'txt_bert': 'v1',
                    'meta_learner': 'v1'
                },
                'warnings': warnings
            }
            return {
                'ensemble_prediction': ensemble_pred,
                'base_predictions': preds,
                'confidence': None,  # Optionally add confidence/range
                'meta': meta
            }

# Example usage
if __name__ == "__main__":
    engine = EnsembleInferenceEngine('models')
    result = engine.predict(
        tabular=[1.2, 3.4, 5.6, 7.8],
        image_path='example.jpg',
        text='Excellent condition, low mileage.'
    )
    print(result)
import joblib
from ml.ensemble import EnsembleValuator

_ensemble = None

def load_ensemble():
    global _ensemble
    if _ensemble is None:
        xgb = joblib.load("xgb_model.joblib")
        dnn = joblib.load("dnn_model.pt")
        cnn = joblib.load("cnn_model.pt")
        bert = joblib.load("bert_model.pt")
        meta = joblib.load("meta_learner.joblib")
        _ensemble = EnsembleValuator(xgb, dnn, cnn, bert, meta)

def predict_value(val_input, img=None, text=None):
    load_ensemble()
    X_tab = ... # Extract tabular features
    X_img = ... # Preprocess image if present
    X_txt = ... # Preprocess text if present
    return _ensemble.predict(X_tab, X_img, X_txt)
